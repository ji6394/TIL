{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자동화하기\n",
    "# 이어서 쓸 때 save_to_file과 append_to_file 함수에 mode의 파라미터를 'a'로 변경해보기\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlencode\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from fake_useragent import UserAgent\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 설정\n",
    "QUERY = '쿠팡'\n",
    "search_QUERY = urlencode({'subquery': QUERY}, encoding='utf-8')\n",
    "URL = f\"https://www.fmkorea.com/search.php?mid=football_korean&search_keyword={QUERY}&search_target=title_content\"\n",
    "\n",
    "def get_posts(page_num):\n",
    "    global QUERY\n",
    "    posts = []\n",
    "    for page in range(page_num + 1):\n",
    "        # 페이지 넘기기\n",
    "        board_link = f\"https://www.fmkorea.com/search.php?mid=football_korean&search_keyword={QUERY}&search_target=title_content&page={page+1}\"\n",
    "        req = requests.get(board_link)\n",
    "        print(req.status_code)\n",
    "        soup = BeautifulSoup(req.text, 'html.parser')\n",
    "        # 전체 20개의 게시글의 링크를 posts에 append하는 과정\n",
    "        tds = soup.find_all('td', {'class': 'title hotdeal_var8'})\n",
    "        for td in tds:\n",
    "            post = td.find('a', {'class': 'hx'})\n",
    "            if post is not None:\n",
    "                posts.append(post['href'])\n",
    "    print(f\"총 {len(posts)}개의 글 링크를 찾았습니다.\")\n",
    "    # 게시글 링크 csv로 저장\n",
    "    post_file = open(f\"FMKOREA_{QUERY}_{page_num}pages_inner_links.csv\", mode='w', encoding='utf-8')\n",
    "    writer = csv.writer(post_file)\n",
    "    for post in posts:\n",
    "        writer.writerow([post])\n",
    "    post_file.close()\n",
    "    return posts\n",
    "\n",
    "def extract_info(url):\n",
    "    full_url = 'http://fmkorea.com'+url\n",
    "    chrome_options = Options()\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(full_url)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    title = soup.find('span', {'class': 'np_18px_span'}).get_text(strip=True)\n",
    "    user_id = soup.find('a', {'class': lambda x: x and x.startswith('member_')}).get_text(strip=True)\n",
    "    post_time = soup.find('span', {'class': 'date m_no'}).get_text(strip=True)\n",
    "    post = soup.find('div', class_='xe_content').get_text(separator = ' ', strip=True)\n",
    "    # 댓글 수 추출\n",
    "    try:\n",
    "        # 댓글 수 추출\n",
    "        reply_cnt_div = soup.find('div', class_='fdb_tag bg_f_f9 css3pie')\n",
    "        if reply_cnt_div:\n",
    "            reply_cnt = int(reply_cnt_div.find('b').text)\n",
    "        else:\n",
    "            reply_cnt = 0\n",
    "    except (AttributeError, ValueError):\n",
    "        reply_cnt = 0\n",
    "    reply_content = []\n",
    "    if reply_cnt != 0:\n",
    "        #페이지 숫자 확인\n",
    "        paging_div = soup.find('div', class_ = 'bd_pg clear')\n",
    "        if paging_div:\n",
    "            for tag in paging_div.find('strong'):\n",
    "                if tag.name == 'a' and 'direction' in tag.get('class',[]):\n",
    "                    continue\n",
    "                try:\n",
    "                    cmt_page_max = int(tag.get_text())\n",
    "                except ValueError:\n",
    "                    continue\n",
    "        else:\n",
    "            cmt_page_max = 1\n",
    "        # 댓글 정보 추가 (댓글 크롤링 부분에 추가)\n",
    "        for i in range(cmt_page_max):\n",
    "            j = cmt_page_max - i\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            # 모든 댓글 항목 찾기\n",
    "            # 댓글이 포함된 ul 태그 찾기\n",
    "            comments_ul = soup.find('ul', class_='fdb_lst_ul')\n",
    "\n",
    "            # 각 댓글 li 태그 찾기\n",
    "            comments = comments_ul.find_all('li', class_='fdb_itm')\n",
    "            for comment in comments:\n",
    "                cmt_reply = False\n",
    "                reply_prefix = ''\n",
    "                # 대댓글 여부 확인\n",
    "                if 're' in comment.get('class', []):\n",
    "                    cmt_reply = True\n",
    "                    reply_prefix = 'ㄴ'\n",
    "                \n",
    "                # 댓글 작성자 추출\n",
    "                author = comment.find('a', class_='member_plate').text.strip()\n",
    "                \n",
    "                # 댓글 작성 시간 추출\n",
    "                date = comment.find('span', class_='date').text.strip()\n",
    "                \n",
    "                # 댓글 내용 추출\n",
    "                content = comment.find('div', class_='xe_content').text.strip()\n",
    "                if cmt_reply:\n",
    "                    content = f\"{reply_prefix} {content}\"\n",
    "                reply_content.append({'author':author, 'text':content, 'date':date})\n",
    "            if j>1:\n",
    "                driver.get(f'https://www.fmkorea.com/search.php?mid=football_korean&sort_index=pop&order_type=desc&search_target=title_content&document_srl=7052178769&search_keyword={QUERY}&listStyle=webzine&cpage={j-1}')\n",
    "                time.sleep(2)\n",
    "\n",
    "    data = {'title': title, 'user_id': user_id, 'post_time': post_time, 'post': post, 'reply_cnt': reply_cnt, 'reply_content': reply_content}\n",
    "\n",
    "    # 댓글이 있다면 딕셔너리에 추가\n",
    "    if reply_cnt != 0:\n",
    "        for i, reply_info in enumerate(reply_content):\n",
    "            data[f'reply_{i+1}_author'] = reply_info['author']\n",
    "            data[f'reply_{i+1}_text'] = reply_info['text']\n",
    "            data[f'reply_{i+1}_date'] = reply_info['date']\n",
    "            \n",
    "\n",
    "    print(url, '완료')\n",
    "    return data\n",
    "\n",
    "def get_contents(posts):\n",
    "    for post_link in posts:\n",
    "        content = extract_info(post_link)\n",
    "        append_to_file(f\"FMKOREA_{QUERY}_.csv\", content)\n",
    "    return print(\"모든 작업이 완료되었습니다.\")\n",
    "\n",
    "def save_to_file():\n",
    "    file = open(f'FMKOREA_{QUERY}_.csv', mode='a', encoding='utf-8')\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['title', 'user_id', 'post_time', 'post', 'reply_cnt', 'reply_author', 'reply_content'])\n",
    "    file.close()\n",
    "    return file\n",
    "\n",
    "def append_to_file(file_name, data):\n",
    "    file = open(file_name, mode='a', encoding='utf-8', newline='')  # newline 추가\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write main post data to CSV\n",
    "    main_post_row = [\n",
    "        data['title'],\n",
    "        data['user_id'],\n",
    "        data['post_time'],\n",
    "        data['post'],\n",
    "        data['reply_cnt']\n",
    "    ]\n",
    "\n",
    "    # Check if there are replies\n",
    "    if 'reply_content' in data and data['reply_cnt'] != 0:\n",
    "        # Write main post data along with reply data to CSV\n",
    "        for i, reply_info in enumerate(data['reply_content']):\n",
    "            writer.writerow(main_post_row + [\n",
    "                reply_info.get('author', ''),  # Reply author\n",
    "                reply_info.get('text', ''),  # Reply text\n",
    "                reply_info.get('date', '')\n",
    "            ])\n",
    "    else:\n",
    "        # Write only main post data to CSV\n",
    "        writer.writerow(main_post_row + ['']*3)\n",
    "\n",
    "    file.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "총 40개의 글 링크를 찾았습니다.\n"
     ]
    }
   ],
   "source": [
    "# 크롤링할 페이지 수 설정\n",
    "PAGES = 499\n",
    "# 게시글 링크 수집\n",
    "post_links = get_posts(PAGES)\n",
    "save_to_file()\n",
    "get_contents(post_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "      <th>post_time</th>\n",
       "      <th>post</th>\n",
       "      <th>reply_cnt</th>\n",
       "      <th>reply_author</th>\n",
       "      <th>reply_content</th>\n",
       "      <th>reply_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TV로보는데 화질 너무 좋다</td>\n",
       "      <td>호세피렐라</td>\n",
       "      <td>2023.07.27 20:04</td>\n",
       "      <td>쿠팡 고마워..</td>\n",
       "      <td>5</td>\n",
       "      <td>춥지않던겨울</td>\n",
       "      <td>티비 몇번에서 하나요</td>\n",
       "      <td>2023.07.27 20:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TV로보는데 화질 너무 좋다</td>\n",
       "      <td>호세피렐라</td>\n",
       "      <td>2023.07.27 20:04</td>\n",
       "      <td>쿠팡 고마워..</td>\n",
       "      <td>5</td>\n",
       "      <td>호세피렐라</td>\n",
       "      <td>ㄴ 춥지않던겨울 쿠팡플레이로 튼거에요</td>\n",
       "      <td>2023.07.27 20:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TV로보는데 화질 너무 좋다</td>\n",
       "      <td>호세피렐라</td>\n",
       "      <td>2023.07.27 20:04</td>\n",
       "      <td>쿠팡 고마워..</td>\n",
       "      <td>5</td>\n",
       "      <td>간지붐송</td>\n",
       "      <td>ㄴ 춥지않던겨울 쿠플 독점이라 TV에 연결해서 보는 사람들 꽤 있음</td>\n",
       "      <td>2023.07.27 20:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TV로보는데 화질 너무 좋다</td>\n",
       "      <td>호세피렐라</td>\n",
       "      <td>2023.07.27 20:04</td>\n",
       "      <td>쿠팡 고마워..</td>\n",
       "      <td>5</td>\n",
       "      <td>전진우</td>\n",
       "      <td>현장음도 적절하니 넘 좋음ㅋㅋㅋ</td>\n",
       "      <td>2023.07.27 20:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TV로보는데 화질 너무 좋다</td>\n",
       "      <td>호세피렐라</td>\n",
       "      <td>2023.07.27 20:04</td>\n",
       "      <td>쿠팡 고마워..</td>\n",
       "      <td>5</td>\n",
       "      <td>Nasir</td>\n",
       "      <td>너무 좋다 화질</td>\n",
       "      <td>2023.07.27 20:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2864</th>\n",
       "      <td>7/16 K리그 라인업</td>\n",
       "      <td>킹짱구</td>\n",
       "      <td>2023.07.15 23:52</td>\n",
       "      <td>[ 전북 vs 수 원 F C ] 라인업 - 19:00 킥오프 | 쿠팡 플레이 , J...</td>\n",
       "      <td>8</td>\n",
       "      <td>압델하크누리</td>\n",
       "      <td>ㄴ 핀란드망고 한숨쉬며 보던 개리그를한숨놓고 보겠네</td>\n",
       "      <td>2023.07.15 23:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2865</th>\n",
       "      <td>7/16 K리그 라인업</td>\n",
       "      <td>킹짱구</td>\n",
       "      <td>2023.07.15 23:52</td>\n",
       "      <td>[ 전북 vs 수 원 F C ] 라인업 - 19:00 킥오프 | 쿠팡 플레이 , J...</td>\n",
       "      <td>8</td>\n",
       "      <td>야스</td>\n",
       "      <td>지나치게 열심히 하는 판쟝이 들어왔다</td>\n",
       "      <td>2023.07.15 23:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2866</th>\n",
       "      <td>7/16 K리그 라인업</td>\n",
       "      <td>킹짱구</td>\n",
       "      <td>2023.07.15 23:52</td>\n",
       "      <td>[ 전북 vs 수 원 F C ] 라인업 - 19:00 킥오프 | 쿠팡 플레이 , J...</td>\n",
       "      <td>8</td>\n",
       "      <td>엔데버</td>\n",
       "      <td>스카이 스포츠 분신술씀?</td>\n",
       "      <td>2023.07.15 23:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2867</th>\n",
       "      <td>7/16 K리그 라인업</td>\n",
       "      <td>킹짱구</td>\n",
       "      <td>2023.07.15 23:52</td>\n",
       "      <td>[ 전북 vs 수 원 F C ] 라인업 - 19:00 킥오프 | 쿠팡 플레이 , J...</td>\n",
       "      <td>8</td>\n",
       "      <td>킹짱구</td>\n",
       "      <td>ㄴ 엔데버 며칠전에 만들어 논거라 바꼈음 ㅎㅅㅎ</td>\n",
       "      <td>2023.07.16 00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2868</th>\n",
       "      <td>7/16 K리그 라인업</td>\n",
       "      <td>킹짱구</td>\n",
       "      <td>2023.07.15 23:52</td>\n",
       "      <td>[ 전북 vs 수 원 F C ] 라인업 - 19:00 킥오프 | 쿠팡 플레이 , J...</td>\n",
       "      <td>8</td>\n",
       "      <td>스피드볼</td>\n",
       "      <td>인천 주전 대거 빠졌네 좆망</td>\n",
       "      <td>2023.07.16 17:50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2868 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                title user_id         post_time  \\\n",
       "1     TV로보는데 화질 너무 좋다   호세피렐라  2023.07.27 20:04   \n",
       "2     TV로보는데 화질 너무 좋다   호세피렐라  2023.07.27 20:04   \n",
       "3     TV로보는데 화질 너무 좋다   호세피렐라  2023.07.27 20:04   \n",
       "4     TV로보는데 화질 너무 좋다   호세피렐라  2023.07.27 20:04   \n",
       "5     TV로보는데 화질 너무 좋다   호세피렐라  2023.07.27 20:04   \n",
       "...               ...     ...               ...   \n",
       "2864     7/16 K리그 라인업     킹짱구  2023.07.15 23:52   \n",
       "2865     7/16 K리그 라인업     킹짱구  2023.07.15 23:52   \n",
       "2866     7/16 K리그 라인업     킹짱구  2023.07.15 23:52   \n",
       "2867     7/16 K리그 라인업     킹짱구  2023.07.15 23:52   \n",
       "2868     7/16 K리그 라인업     킹짱구  2023.07.15 23:52   \n",
       "\n",
       "                                                   post reply_cnt  \\\n",
       "1                                              쿠팡 고마워..         5   \n",
       "2                                              쿠팡 고마워..         5   \n",
       "3                                              쿠팡 고마워..         5   \n",
       "4                                              쿠팡 고마워..         5   \n",
       "5                                              쿠팡 고마워..         5   \n",
       "...                                                 ...       ...   \n",
       "2864  [ 전북 vs 수 원 F C ] 라인업 - 19:00 킥오프 | 쿠팡 플레이 , J...         8   \n",
       "2865  [ 전북 vs 수 원 F C ] 라인업 - 19:00 킥오프 | 쿠팡 플레이 , J...         8   \n",
       "2866  [ 전북 vs 수 원 F C ] 라인업 - 19:00 킥오프 | 쿠팡 플레이 , J...         8   \n",
       "2867  [ 전북 vs 수 원 F C ] 라인업 - 19:00 킥오프 | 쿠팡 플레이 , J...         8   \n",
       "2868  [ 전북 vs 수 원 F C ] 라인업 - 19:00 킥오프 | 쿠팡 플레이 , J...         8   \n",
       "\n",
       "     reply_author                          reply_content        reply_date  \n",
       "1          춥지않던겨울                            티비 몇번에서 하나요  2023.07.27 20:04  \n",
       "2           호세피렐라                   ㄴ 춥지않던겨울 쿠팡플레이로 튼거에요  2023.07.27 20:04  \n",
       "3            간지붐송  ㄴ 춥지않던겨울 쿠플 독점이라 TV에 연결해서 보는 사람들 꽤 있음  2023.07.27 20:05  \n",
       "4             전진우                      현장음도 적절하니 넘 좋음ㅋㅋㅋ  2023.07.27 20:04  \n",
       "5           Nasir                               너무 좋다 화질  2023.07.27 20:05  \n",
       "...           ...                                    ...               ...  \n",
       "2864       압델하크누리           ㄴ 핀란드망고 한숨쉬며 보던 개리그를한숨놓고 보겠네  2023.07.15 23:52  \n",
       "2865           야스                   지나치게 열심히 하는 판쟝이 들어왔다  2023.07.15 23:52  \n",
       "2866          엔데버                          스카이 스포츠 분신술씀?  2023.07.15 23:55  \n",
       "2867          킹짱구             ㄴ 엔데버 며칠전에 만들어 논거라 바꼈음 ㅎㅅㅎ  2023.07.16 00:07  \n",
       "2868         스피드볼                        인천 주전 대거 빠졌네 좆망  2023.07.16 17:50  \n",
       "\n",
       "[2868 rows x 8 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('FMKOREA_쿠팡_.csv', names=['title','user_id','post_time','post','reply_cnt','reply_author','reply_content','reply_date'])\n",
    "df=df.drop(0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sda",
   "language": "python",
   "name": "sda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
