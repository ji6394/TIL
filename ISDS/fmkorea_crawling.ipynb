{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자동화하기\n",
    "# 이어서 쓸 때 save_to_file과 append_to_file 함수에 mode의 파라미터를 'a'로 변경해보기\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlencode\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from fake_useragent import UserAgent\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 설정\n",
    "QUERY = '쿠팡'\n",
    "search_QUERY = urlencode({'subquery': QUERY}, encoding='utf-8')\n",
    "URL = f\"https://www.fmkorea.com/search.php?mid=football_korean&search_keyword={QUERY}&search_target=title_content\"\n",
    "\n",
    "def get_posts(page_num):\n",
    "    global QUERY\n",
    "    posts = []\n",
    "    for page in range(page_num + 1):\n",
    "        # 페이지 넘기기\n",
    "        board_link = f\"https://www.fmkorea.com/search.php?mid=football_korean&search_keyword={QUERY}&search_target=title_content&page={page+1}\"\n",
    "        req = requests.get(board_link)\n",
    "        print(req.status_code)\n",
    "        soup = BeautifulSoup(req.text, 'html.parser')\n",
    "        # 전체 20개의 게시글의 링크를 posts에 append하는 과정\n",
    "        tds = soup.find_all('td', {'class': 'title hotdeal_var8'})\n",
    "        for td in tds:\n",
    "            post = td.find('a', {'class': 'hx'})\n",
    "            if post is not None:\n",
    "                posts.append(post['href'])\n",
    "    print(f\"총 {len(posts)}개의 글 링크를 찾았습니다.\")\n",
    "    # 게시글 링크 csv로 저장\n",
    "    post_file = open(f\"FMKOREA_{QUERY}_{page_num}pages_inner_links.csv\", mode='w', encoding='utf-8')\n",
    "    writer = csv.writer(post_file)\n",
    "    for post in posts:\n",
    "        writer.writerow([post])\n",
    "    post_file.close()\n",
    "    return posts\n",
    "\n",
    "def extract_info(url):\n",
    "    full_url = 'http://fmkorea.com'+url\n",
    "    chrome_options = Options()\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(full_url)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    title = soup.find('span', {'class': 'np_18px_span'}).get_text(strip=True)\n",
    "    user_id = soup.find('a', {'class': lambda x: x and x.startswith('member_')}).get_text(strip=True)\n",
    "    post_time = soup.find('span', {'class': 'date m_no'}).get_text(strip=True)\n",
    "    post = soup.find('div', class_='xe_content').get_text(separator = ' ', strip=True)\n",
    "    # 댓글 수 추출\n",
    "    try:\n",
    "        # 댓글 수 추출\n",
    "        reply_cnt_div = soup.find('div', class_='fdb_tag bg_f_f9 css3pie')\n",
    "        if reply_cnt_div:\n",
    "            reply_cnt = int(reply_cnt_div.find('b').text)\n",
    "        else:\n",
    "            reply_cnt = 0\n",
    "    except (AttributeError, ValueError):\n",
    "        reply_cnt = 0\n",
    "    reply_content = []\n",
    "    if reply_cnt != 0:\n",
    "        #페이지 숫자 확인\n",
    "        paging_div = soup.find('div', class_ = 'bd_pg clear')\n",
    "        if paging_div:\n",
    "            for tag in paging_div.find('strong'):\n",
    "                if tag.name == 'a' and 'direction' in tag.get('class',[]):\n",
    "                    continue\n",
    "                try:\n",
    "                    cmt_page_max = int(tag.get_text())\n",
    "                except ValueError:\n",
    "                    continue\n",
    "        else:\n",
    "            cmt_page_max = 1\n",
    "        # 댓글 정보 추가 (댓글 크롤링 부분에 추가)\n",
    "        for i in range(cmt_page_max):\n",
    "            j = cmt_page_max - i\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            # 모든 댓글 항목 찾기\n",
    "            # 댓글이 포함된 ul 태그 찾기\n",
    "            comments_ul = soup.find('ul', class_='fdb_lst_ul')\n",
    "\n",
    "            # 각 댓글 li 태그 찾기\n",
    "            comments = comments_ul.find_all('li', class_='fdb_itm')\n",
    "            for comment in comments:\n",
    "                cmt_reply = False\n",
    "                reply_prefix = ''\n",
    "                # 대댓글 여부 확인\n",
    "                if 're' in comment.get('class', []):\n",
    "                    cmt_reply = True\n",
    "                    reply_prefix = 'ㄴ'\n",
    "                \n",
    "                # 댓글 작성자 추출\n",
    "                author = comment.find('a', class_='member_plate').text.strip()\n",
    "                \n",
    "                # 댓글 작성 시간 추출\n",
    "                date = comment.find('span', class_='date').text.strip()\n",
    "                \n",
    "                # 댓글 내용 추출\n",
    "                content = comment.find('div', class_='xe_content').text.strip()\n",
    "                if cmt_reply:\n",
    "                    content = f\"{reply_prefix} {content}\"\n",
    "                reply_content.append({'author':author, 'text':content, 'date':date})\n",
    "            if j>1:\n",
    "                driver.get(f'https://www.fmkorea.com/search.php?mid=football_korean&sort_index=pop&order_type=desc&search_target=title_content&document_srl=7052178769&search_keyword={QUERY}&listStyle=webzine&cpage={j-1}')\n",
    "                time.sleep(2)\n",
    "\n",
    "    data = {'title': title, 'user_id': user_id, 'post_time': post_time, 'post': post, 'reply_cnt': reply_cnt, 'reply_content': reply_content}\n",
    "\n",
    "    # 댓글이 있다면 딕셔너리에 추가\n",
    "    if reply_cnt != 0:\n",
    "        for i, reply_info in enumerate(reply_content):\n",
    "            data[f'reply_{i+1}_author'] = reply_info['author']\n",
    "            data[f'reply_{i+1}_text'] = reply_info['text']\n",
    "            data[f'reply_{i+1}_date'] = reply_info['date']\n",
    "            \n",
    "\n",
    "    print(url, '완료')\n",
    "    return data\n",
    "\n",
    "def get_contents(posts):\n",
    "    for post_link in posts:\n",
    "        content = extract_info(post_link)\n",
    "        append_to_file(f\"FMKOREA_{QUERY}_.csv\", content)\n",
    "    return print(\"모든 작업이 완료되었습니다.\")\n",
    "\n",
    "def save_to_file():\n",
    "    file = open(f'FMKOREA_{QUERY}_.csv', mode='a', encoding='utf-8')\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['title', 'user_id', 'post_time', 'post', 'reply_cnt', 'reply_author', 'reply_content'])\n",
    "    file.close()\n",
    "    return file\n",
    "\n",
    "def append_to_file(file_name, data):\n",
    "    file = open(file_name, mode='a', encoding='utf-8', newline='')  # newline 추가\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write main post data to CSV\n",
    "    main_post_row = [\n",
    "        data['title'],\n",
    "        data['user_id'],\n",
    "        data['post_time'],\n",
    "        data['post'],\n",
    "        data['reply_cnt']\n",
    "    ]\n",
    "\n",
    "    # Check if there are replies\n",
    "    if 'reply_content' in data and data['reply_cnt'] != 0:\n",
    "        # Write main post data along with reply data to CSV\n",
    "        for i, reply_info in enumerate(data['reply_content']):\n",
    "            writer.writerow(main_post_row + [\n",
    "                reply_info.get('author', ''),  # Reply author\n",
    "                reply_info.get('text', ''),  # Reply text\n",
    "                reply_info.get('date', '')\n",
    "            ])\n",
    "    else:\n",
    "        # Write only main post data to CSV\n",
    "        writer.writerow(main_post_row + ['']*3)\n",
    "\n",
    "    file.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430\n",
      "430\n",
      "430\n",
      "430\n",
      "430\n",
      "430\n",
      "430\n",
      "430\n",
      "430\n",
      "430\n",
      "430\n",
      "430\n",
      "430\n",
      "430\n",
      "430\n",
      "430\n",
      "430\n",
      "430\n",
      "430\n",
      "430\n",
      "430\n",
      "430\n",
      "430\n",
      "430\n",
      "430\n",
      "430\n",
      "430\n",
      "430\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m PAGES \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m499\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 게시글 링크 수집\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m post_links \u001b[38;5;241m=\u001b[39m \u001b[43mget_posts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPAGES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m save_to_file()\n\u001b[0;32m      6\u001b[0m get_contents(post_links)\n",
      "Cell \u001b[1;32mIn[58], line 12\u001b[0m, in \u001b[0;36mget_posts\u001b[1;34m(page_num)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(page_num \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# 페이지 넘기기\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     board_link \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.fmkorea.com/search.php?mid=football_korean&search_keyword=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mQUERY\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&search_target=title_content&page=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 12\u001b[0m     req \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboard_link\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(req\u001b[38;5;241m.\u001b[39mstatus_code)\n\u001b[0;32m     14\u001b[0m     soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(req\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\82108\\anaconda3\\envs\\sda\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\82108\\anaconda3\\envs\\sda\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\82108\\anaconda3\\envs\\sda\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\82108\\anaconda3\\envs\\sda\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\82108\\anaconda3\\envs\\sda\\lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\82108\\anaconda3\\envs\\sda\\lib\\site-packages\\urllib3\\connectionpool.py:793\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    790\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 793\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    794\u001b[0m     conn,\n\u001b[0;32m    795\u001b[0m     method,\n\u001b[0;32m    796\u001b[0m     url,\n\u001b[0;32m    797\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    798\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    799\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    800\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    801\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    802\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    803\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    804\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    805\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    806\u001b[0m )\n\u001b[0;32m    808\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    809\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\82108\\anaconda3\\envs\\sda\\lib\\site-packages\\urllib3\\connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 467\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mconn\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[1;32mc:\\Users\\82108\\anaconda3\\envs\\sda\\lib\\site-packages\\urllib3\\connectionpool.py:1099\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[1;32m-> 1099\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mproxy_is_verified:\n",
      "File \u001b[1;32mc:\\Users\\82108\\anaconda3\\envs\\sda\\lib\\site-packages\\urllib3\\connection.py:653\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    650\u001b[0m \u001b[38;5;66;03m# Remove trailing '.' from fqdn hostnames to allow certificate validation\u001b[39;00m\n\u001b[0;32m    651\u001b[0m server_hostname_rm_dot \u001b[38;5;241m=\u001b[39m server_hostname\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 653\u001b[0m sock_and_verified \u001b[38;5;241m=\u001b[39m \u001b[43m_ssl_wrap_socket_and_match_hostname\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_reqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    660\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    661\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcert_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname_rm_dot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock_and_verified\u001b[38;5;241m.\u001b[39msocket\n\u001b[0;32m    673\u001b[0m \u001b[38;5;66;03m# Forwarding proxies can never have a verified target since\u001b[39;00m\n\u001b[0;32m    674\u001b[0m \u001b[38;5;66;03m# the proxy is the one doing the verification. Should instead\u001b[39;00m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;66;03m# use a CONNECT tunnel in order to verify the target.\u001b[39;00m\n\u001b[0;32m    676\u001b[0m \u001b[38;5;66;03m# See: https://github.com/urllib3/urllib3/issues/3267.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\82108\\anaconda3\\envs\\sda\\lib\\site-packages\\urllib3\\connection.py:806\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_and_match_hostname\u001b[1;34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[0m\n\u001b[0;32m    803\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_ipaddress(normalized):\n\u001b[0;32m    804\u001b[0m         server_hostname \u001b[38;5;241m=\u001b[39m normalized\n\u001b[1;32m--> 806\u001b[0m ssl_sock \u001b[38;5;241m=\u001b[39m \u001b[43mssl_wrap_socket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    807\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    808\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeyfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    809\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcertfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    810\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    811\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    812\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    813\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    817\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    819\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m assert_fingerprint:\n",
      "File \u001b[1;32mc:\\Users\\82108\\anaconda3\\envs\\sda\\lib\\site-packages\\urllib3\\util\\ssl_.py:440\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ca_certs \u001b[38;5;129;01mor\u001b[39;00m ca_cert_dir \u001b[38;5;129;01mor\u001b[39;00m ca_cert_data:\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 440\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_verify_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    442\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 크롤링할 페이지 수 설정\n",
    "PAGES = 499\n",
    "# 게시글 링크 수집\n",
    "post_links = get_posts(PAGES)\n",
    "save_to_file()\n",
    "get_contents(post_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "      <th>post_time</th>\n",
       "      <th>post</th>\n",
       "      <th>reply_cnt</th>\n",
       "      <th>reply_author</th>\n",
       "      <th>reply_content</th>\n",
       "      <th>reply_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TV로보는데 화질 너무 좋다</td>\n",
       "      <td>호세피렐라</td>\n",
       "      <td>2023.07.27 20:04</td>\n",
       "      <td>쿠팡 고마워..</td>\n",
       "      <td>5</td>\n",
       "      <td>춥지않던겨울</td>\n",
       "      <td>티비 몇번에서 하나요</td>\n",
       "      <td>2023.07.27 20:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TV로보는데 화질 너무 좋다</td>\n",
       "      <td>호세피렐라</td>\n",
       "      <td>2023.07.27 20:04</td>\n",
       "      <td>쿠팡 고마워..</td>\n",
       "      <td>5</td>\n",
       "      <td>호세피렐라</td>\n",
       "      <td>ㄴ 춥지않던겨울 쿠팡플레이로 튼거에요</td>\n",
       "      <td>2023.07.27 20:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TV로보는데 화질 너무 좋다</td>\n",
       "      <td>호세피렐라</td>\n",
       "      <td>2023.07.27 20:04</td>\n",
       "      <td>쿠팡 고마워..</td>\n",
       "      <td>5</td>\n",
       "      <td>간지붐송</td>\n",
       "      <td>ㄴ 춥지않던겨울 쿠플 독점이라 TV에 연결해서 보는 사람들 꽤 있음</td>\n",
       "      <td>2023.07.27 20:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TV로보는데 화질 너무 좋다</td>\n",
       "      <td>호세피렐라</td>\n",
       "      <td>2023.07.27 20:04</td>\n",
       "      <td>쿠팡 고마워..</td>\n",
       "      <td>5</td>\n",
       "      <td>전진우</td>\n",
       "      <td>현장음도 적절하니 넘 좋음ㅋㅋㅋ</td>\n",
       "      <td>2023.07.27 20:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TV로보는데 화질 너무 좋다</td>\n",
       "      <td>호세피렐라</td>\n",
       "      <td>2023.07.27 20:04</td>\n",
       "      <td>쿠팡 고마워..</td>\n",
       "      <td>5</td>\n",
       "      <td>Nasir</td>\n",
       "      <td>너무 좋다 화질</td>\n",
       "      <td>2023.07.27 20:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2864</th>\n",
       "      <td>7/16 K리그 라인업</td>\n",
       "      <td>킹짱구</td>\n",
       "      <td>2023.07.15 23:52</td>\n",
       "      <td>[ 전북 vs 수 원 F C ] 라인업 - 19:00 킥오프 | 쿠팡 플레이 , J...</td>\n",
       "      <td>8</td>\n",
       "      <td>압델하크누리</td>\n",
       "      <td>ㄴ 핀란드망고 한숨쉬며 보던 개리그를한숨놓고 보겠네</td>\n",
       "      <td>2023.07.15 23:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2865</th>\n",
       "      <td>7/16 K리그 라인업</td>\n",
       "      <td>킹짱구</td>\n",
       "      <td>2023.07.15 23:52</td>\n",
       "      <td>[ 전북 vs 수 원 F C ] 라인업 - 19:00 킥오프 | 쿠팡 플레이 , J...</td>\n",
       "      <td>8</td>\n",
       "      <td>야스</td>\n",
       "      <td>지나치게 열심히 하는 판쟝이 들어왔다</td>\n",
       "      <td>2023.07.15 23:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2866</th>\n",
       "      <td>7/16 K리그 라인업</td>\n",
       "      <td>킹짱구</td>\n",
       "      <td>2023.07.15 23:52</td>\n",
       "      <td>[ 전북 vs 수 원 F C ] 라인업 - 19:00 킥오프 | 쿠팡 플레이 , J...</td>\n",
       "      <td>8</td>\n",
       "      <td>엔데버</td>\n",
       "      <td>스카이 스포츠 분신술씀?</td>\n",
       "      <td>2023.07.15 23:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2867</th>\n",
       "      <td>7/16 K리그 라인업</td>\n",
       "      <td>킹짱구</td>\n",
       "      <td>2023.07.15 23:52</td>\n",
       "      <td>[ 전북 vs 수 원 F C ] 라인업 - 19:00 킥오프 | 쿠팡 플레이 , J...</td>\n",
       "      <td>8</td>\n",
       "      <td>킹짱구</td>\n",
       "      <td>ㄴ 엔데버 며칠전에 만들어 논거라 바꼈음 ㅎㅅㅎ</td>\n",
       "      <td>2023.07.16 00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2868</th>\n",
       "      <td>7/16 K리그 라인업</td>\n",
       "      <td>킹짱구</td>\n",
       "      <td>2023.07.15 23:52</td>\n",
       "      <td>[ 전북 vs 수 원 F C ] 라인업 - 19:00 킥오프 | 쿠팡 플레이 , J...</td>\n",
       "      <td>8</td>\n",
       "      <td>스피드볼</td>\n",
       "      <td>인천 주전 대거 빠졌네 좆망</td>\n",
       "      <td>2023.07.16 17:50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2868 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                title user_id         post_time  \\\n",
       "1     TV로보는데 화질 너무 좋다   호세피렐라  2023.07.27 20:04   \n",
       "2     TV로보는데 화질 너무 좋다   호세피렐라  2023.07.27 20:04   \n",
       "3     TV로보는데 화질 너무 좋다   호세피렐라  2023.07.27 20:04   \n",
       "4     TV로보는데 화질 너무 좋다   호세피렐라  2023.07.27 20:04   \n",
       "5     TV로보는데 화질 너무 좋다   호세피렐라  2023.07.27 20:04   \n",
       "...               ...     ...               ...   \n",
       "2864     7/16 K리그 라인업     킹짱구  2023.07.15 23:52   \n",
       "2865     7/16 K리그 라인업     킹짱구  2023.07.15 23:52   \n",
       "2866     7/16 K리그 라인업     킹짱구  2023.07.15 23:52   \n",
       "2867     7/16 K리그 라인업     킹짱구  2023.07.15 23:52   \n",
       "2868     7/16 K리그 라인업     킹짱구  2023.07.15 23:52   \n",
       "\n",
       "                                                   post reply_cnt  \\\n",
       "1                                              쿠팡 고마워..         5   \n",
       "2                                              쿠팡 고마워..         5   \n",
       "3                                              쿠팡 고마워..         5   \n",
       "4                                              쿠팡 고마워..         5   \n",
       "5                                              쿠팡 고마워..         5   \n",
       "...                                                 ...       ...   \n",
       "2864  [ 전북 vs 수 원 F C ] 라인업 - 19:00 킥오프 | 쿠팡 플레이 , J...         8   \n",
       "2865  [ 전북 vs 수 원 F C ] 라인업 - 19:00 킥오프 | 쿠팡 플레이 , J...         8   \n",
       "2866  [ 전북 vs 수 원 F C ] 라인업 - 19:00 킥오프 | 쿠팡 플레이 , J...         8   \n",
       "2867  [ 전북 vs 수 원 F C ] 라인업 - 19:00 킥오프 | 쿠팡 플레이 , J...         8   \n",
       "2868  [ 전북 vs 수 원 F C ] 라인업 - 19:00 킥오프 | 쿠팡 플레이 , J...         8   \n",
       "\n",
       "     reply_author                          reply_content        reply_date  \n",
       "1          춥지않던겨울                            티비 몇번에서 하나요  2023.07.27 20:04  \n",
       "2           호세피렐라                   ㄴ 춥지않던겨울 쿠팡플레이로 튼거에요  2023.07.27 20:04  \n",
       "3            간지붐송  ㄴ 춥지않던겨울 쿠플 독점이라 TV에 연결해서 보는 사람들 꽤 있음  2023.07.27 20:05  \n",
       "4             전진우                      현장음도 적절하니 넘 좋음ㅋㅋㅋ  2023.07.27 20:04  \n",
       "5           Nasir                               너무 좋다 화질  2023.07.27 20:05  \n",
       "...           ...                                    ...               ...  \n",
       "2864       압델하크누리           ㄴ 핀란드망고 한숨쉬며 보던 개리그를한숨놓고 보겠네  2023.07.15 23:52  \n",
       "2865           야스                   지나치게 열심히 하는 판쟝이 들어왔다  2023.07.15 23:52  \n",
       "2866          엔데버                          스카이 스포츠 분신술씀?  2023.07.15 23:55  \n",
       "2867          킹짱구             ㄴ 엔데버 며칠전에 만들어 논거라 바꼈음 ㅎㅅㅎ  2023.07.16 00:07  \n",
       "2868         스피드볼                        인천 주전 대거 빠졌네 좆망  2023.07.16 17:50  \n",
       "\n",
       "[2868 rows x 8 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('FMKOREA_쿠팡_.csv', names=['title','user_id','post_time','post','reply_cnt','reply_author','reply_content','reply_date'])\n",
    "df=df.drop(0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 에이전트 추가\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "# 변수 설정\n",
    "QUERY = '쿠팡'\n",
    "search_QUERY = urlencode({'subquery': QUERY}, encoding='utf-8')\n",
    "URL = f\"https://www.fmkorea.com/search.php?mid=football_korean&search_keyword={QUERY}&search_target=title_content\"\n",
    "\n",
    "def get_posts(page_num):\n",
    "    global QUERY\n",
    "    posts = []\n",
    "    for page in range(page_num + 1):\n",
    "        # 페이지 넘기기\n",
    "        board_link = f\"https://www.fmkorea.com/search.php?mid=football_korean&search_keyword={QUERY}&search_target=title_content&page={page+1}\"\n",
    "        # 요청 시 사용자 에이전트를 추가\n",
    "        req = requests.get(board_link, headers=headers)\n",
    "        print(req.status_code)\n",
    "        if req.status_code == 200:\n",
    "            soup = BeautifulSoup(req.text, 'html.parser')\n",
    "            # 전체 20개의 게시글의 링크를 posts에 append하는 과정\n",
    "            tds = soup.find_all('td', {'class': 'title hotdeal_var8'})\n",
    "            for td in tds:\n",
    "                post = td.find('a', {'class': 'hx'})\n",
    "                if post is not None:\n",
    "                    posts.append(post['href'])\n",
    "        else:\n",
    "            print(\"요청이 제한되었습니다. 일정 시간을 기다린 후 다시 시도해 주세요.\")\n",
    "        # 요청 사이에 지연을 추가\n",
    "        time.sleep(1)  # 1초 지연\n",
    "    print(f\"총 {len(posts)}개의 글 링크를 찾았습니다.\")\n",
    "    # 게시글 링크 csv로 저장\n",
    "    post_file = open(f\"FMKOREA_{QUERY}_{page_num}pages_inner_links.csv\", mode='w', encoding='utf-8')\n",
    "    writer = csv.writer(post_file)\n",
    "    for post in posts:\n",
    "        writer.writerow([post])\n",
    "    post_file.close()\n",
    "    return posts\n",
    "\n",
    "def extract_info(url):\n",
    "    full_url = 'http://fmkorea.com'+url\n",
    "    chrome_options = Options()\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(full_url)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    title = soup.find('span', {'class': 'np_18px_span'}).get_text(strip=True)\n",
    "    user_id = soup.find('a', {'class': lambda x: x and x.startswith('member_')}).get_text(strip=True)\n",
    "    post_time = soup.find('span', {'class': 'date m_no'}).get_text(strip=True)\n",
    "    post = soup.find('div', class_='xe_content').get_text(separator = ' ', strip=True)\n",
    "    # 댓글 수 추출\n",
    "    try:\n",
    "        # 댓글 수 추출\n",
    "        reply_cnt_div = soup.find('div', class_='fdb_tag bg_f_f9 css3pie')\n",
    "        if reply_cnt_div:\n",
    "            reply_cnt = int(reply_cnt_div.find('b').text)\n",
    "        else:\n",
    "            reply_cnt = 0\n",
    "    except (AttributeError, ValueError):\n",
    "        reply_cnt = 0\n",
    "    reply_content = []\n",
    "    if reply_cnt != 0:\n",
    "        #페이지 숫자 확인\n",
    "        paging_div = soup.find('div', class_ = 'bd_pg clear')\n",
    "        if paging_div:\n",
    "            for tag in paging_div.find('strong'):\n",
    "                if tag.name == 'a' and 'direction' in tag.get('class',[]):\n",
    "                    continue\n",
    "                try:\n",
    "                    cmt_page_max = int(tag.get_text())\n",
    "                except ValueError:\n",
    "                    continue\n",
    "        else:\n",
    "            cmt_page_max = 1\n",
    "        # 댓글 정보 추가 (댓글 크롤링 부분에 추가)\n",
    "        for i in range(cmt_page_max):\n",
    "            j = cmt_page_max - i\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            # 모든 댓글 항목 찾기\n",
    "            # 댓글이 포함된 ul 태그 찾기\n",
    "            comments_ul = soup.find('ul', class_='fdb_lst_ul')\n",
    "\n",
    "            # 각 댓글 li 태그 찾기\n",
    "            comments = comments_ul.find_all('li', class_='fdb_itm')\n",
    "            for comment in comments:\n",
    "                cmt_reply = False\n",
    "                reply_prefix = ''\n",
    "                # 대댓글 여부 확인\n",
    "                if 're' in comment.get('class', []):\n",
    "                    cmt_reply = True\n",
    "                    reply_prefix = 'ㄴ'\n",
    "                \n",
    "                # 댓글 작성자 추출\n",
    "                author = comment.find('a', class_='member_plate').text.strip()\n",
    "                \n",
    "                # 댓글 작성 시간 추출\n",
    "                date = comment.find('span', class_='date').text.strip()\n",
    "                \n",
    "                # 댓글 내용 추출\n",
    "                content = comment.find('div', class_='xe_content').text.strip()\n",
    "                if cmt_reply:\n",
    "                    content = f\"{reply_prefix} {content}\"\n",
    "                reply_content.append({'author':author, 'text':content, 'date':date})\n",
    "            if j>1:\n",
    "                driver.get(f'https://www.fmkorea.com/search.php?mid=football_korean&sort_index=pop&order_type=desc&search_target=title_content&document_srl=7052178769&search_keyword={QUERY}&listStyle=webzine&cpage={j-1}')\n",
    "                time.sleep(2)\n",
    "\n",
    "    data = {'title': title, 'user_id': user_id, 'post_time': post_time, 'post': post, 'reply_cnt': reply_cnt, 'reply_content': reply_content}\n",
    "\n",
    "    # 댓글이 있다면 딕셔너리에 추가\n",
    "    if reply_cnt != 0:\n",
    "        for i, reply_info in enumerate(reply_content):\n",
    "            data[f'reply_{i+1}_author'] = reply_info['author']\n",
    "            data[f'reply_{i+1}_text'] = reply_info['text']\n",
    "            data[f'reply_{i+1}_date'] = reply_info['date']\n",
    "            \n",
    "\n",
    "    print(url, '완료')\n",
    "    return data\n",
    "\n",
    "def get_contents(posts):\n",
    "    for post_link in posts:\n",
    "        content = extract_info(post_link)\n",
    "        append_to_file(f\"FMKOREA_{QUERY}_.csv\", content)\n",
    "    return print(\"모든 작업이 완료되었습니다.\")\n",
    "\n",
    "def save_to_file():\n",
    "    file = open(f'FMKOREA_{QUERY}_.csv', mode='a', encoding='utf-8')\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['title', 'user_id', 'post_time', 'post', 'reply_cnt', 'reply_author', 'reply_content'])\n",
    "    file.close()\n",
    "    return file\n",
    "\n",
    "def append_to_file(file_name, data):\n",
    "    file = open(file_name, mode='a', encoding='utf-8', newline='')  # newline 추가\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write main post data to CSV\n",
    "    main_post_row = [\n",
    "        data['title'],\n",
    "        data['user_id'],\n",
    "        data['post_time'],\n",
    "        data['post'],\n",
    "        data['reply_cnt']\n",
    "    ]\n",
    "\n",
    "    # Check if there are replies\n",
    "    if 'reply_content' in data and data['reply_cnt'] != 0:\n",
    "        # Write main post data along with reply data to CSV\n",
    "        for i, reply_info in enumerate(data['reply_content']):\n",
    "            writer.writerow(main_post_row + [\n",
    "                reply_info.get('author', ''),  # Reply author\n",
    "                reply_info.get('text', ''),  # Reply text\n",
    "                reply_info.get('date', '')\n",
    "            ])\n",
    "    else:\n",
    "        # Write only main post data to CSV\n",
    "        writer.writerow(main_post_row + ['']*3)\n",
    "\n",
    "    file.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "430\n",
      "요청이 제한되었습니다. 일정 시간을 기다린 후 다시 시도해 주세요.\n",
      "430\n",
      "요청이 제한되었습니다. 일정 시간을 기다린 후 다시 시도해 주세요.\n",
      "430\n",
      "요청이 제한되었습니다. 일정 시간을 기다린 후 다시 시도해 주세요.\n",
      "430\n",
      "요청이 제한되었습니다. 일정 시간을 기다린 후 다시 시도해 주세요.\n",
      "430\n",
      "요청이 제한되었습니다. 일정 시간을 기다린 후 다시 시도해 주세요.\n",
      "430\n",
      "요청이 제한되었습니다. 일정 시간을 기다린 후 다시 시도해 주세요.\n",
      "430\n",
      "요청이 제한되었습니다. 일정 시간을 기다린 후 다시 시도해 주세요.\n",
      "430\n",
      "요청이 제한되었습니다. 일정 시간을 기다린 후 다시 시도해 주세요.\n",
      "430\n",
      "요청이 제한되었습니다. 일정 시간을 기다린 후 다시 시도해 주세요.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m PAGES \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m499\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 게시글 링크 수집\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m post_links \u001b[38;5;241m=\u001b[39m \u001b[43mget_posts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPAGES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m save_to_file()\n\u001b[0;32m      6\u001b[0m get_contents(post_links)\n",
      "Cell \u001b[1;32mIn[70], line 17\u001b[0m, in \u001b[0;36mget_posts\u001b[1;34m(page_num)\u001b[0m\n\u001b[0;32m     15\u001b[0m board_link \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.fmkorea.com/search.php?mid=football_korean&search_keyword=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mQUERY\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&search_target=title_content&page=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# 요청 시 사용자 에이전트를 추가\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m req \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboard_link\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(req\u001b[38;5;241m.\u001b[39mstatus_code)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m req\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\82108\\anaconda3\\envs\\sda\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\82108\\anaconda3\\envs\\sda\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\82108\\anaconda3\\envs\\sda\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\82108\\anaconda3\\envs\\sda\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\82108\\anaconda3\\envs\\sda\\lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\82108\\anaconda3\\envs\\sda\\lib\\site-packages\\urllib3\\connectionpool.py:793\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    790\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 793\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    794\u001b[0m     conn,\n\u001b[0;32m    795\u001b[0m     method,\n\u001b[0;32m    796\u001b[0m     url,\n\u001b[0;32m    797\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    798\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    799\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    800\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    801\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    802\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    803\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    804\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    805\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    806\u001b[0m )\n\u001b[0;32m    808\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    809\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\82108\\anaconda3\\envs\\sda\\lib\\site-packages\\urllib3\\connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 467\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mconn\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[1;32mc:\\Users\\82108\\anaconda3\\envs\\sda\\lib\\site-packages\\urllib3\\connectionpool.py:1099\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[1;32m-> 1099\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mproxy_is_verified:\n",
      "File \u001b[1;32mc:\\Users\\82108\\anaconda3\\envs\\sda\\lib\\site-packages\\urllib3\\connection.py:653\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    650\u001b[0m \u001b[38;5;66;03m# Remove trailing '.' from fqdn hostnames to allow certificate validation\u001b[39;00m\n\u001b[0;32m    651\u001b[0m server_hostname_rm_dot \u001b[38;5;241m=\u001b[39m server_hostname\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 653\u001b[0m sock_and_verified \u001b[38;5;241m=\u001b[39m \u001b[43m_ssl_wrap_socket_and_match_hostname\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_reqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    660\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    661\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcert_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname_rm_dot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock_and_verified\u001b[38;5;241m.\u001b[39msocket\n\u001b[0;32m    673\u001b[0m \u001b[38;5;66;03m# Forwarding proxies can never have a verified target since\u001b[39;00m\n\u001b[0;32m    674\u001b[0m \u001b[38;5;66;03m# the proxy is the one doing the verification. Should instead\u001b[39;00m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;66;03m# use a CONNECT tunnel in order to verify the target.\u001b[39;00m\n\u001b[0;32m    676\u001b[0m \u001b[38;5;66;03m# See: https://github.com/urllib3/urllib3/issues/3267.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\82108\\anaconda3\\envs\\sda\\lib\\site-packages\\urllib3\\connection.py:806\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_and_match_hostname\u001b[1;34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[0m\n\u001b[0;32m    803\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_ipaddress(normalized):\n\u001b[0;32m    804\u001b[0m         server_hostname \u001b[38;5;241m=\u001b[39m normalized\n\u001b[1;32m--> 806\u001b[0m ssl_sock \u001b[38;5;241m=\u001b[39m \u001b[43mssl_wrap_socket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    807\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    808\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeyfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    809\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcertfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    810\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    811\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    812\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    813\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    817\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    819\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m assert_fingerprint:\n",
      "File \u001b[1;32mc:\\Users\\82108\\anaconda3\\envs\\sda\\lib\\site-packages\\urllib3\\util\\ssl_.py:440\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ca_certs \u001b[38;5;129;01mor\u001b[39;00m ca_cert_dir \u001b[38;5;129;01mor\u001b[39;00m ca_cert_data:\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 440\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_verify_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    442\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 크롤링할 페이지 수 설정\n",
    "PAGES = 499\n",
    "# 게시글 링크 수집\n",
    "post_links = get_posts(PAGES)\n",
    "save_to_file()\n",
    "get_contents(post_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 설정\n",
    "QUERY = '쿠팡'\n",
    "search_QUERY = urlencode({'subquery': QUERY}, encoding='utf-8')\n",
    "URL = f\"https://www.fmkorea.com/search.php?mid=football_korean&search_keyword={QUERY}&search_target=title_content\"\n",
    "\n",
    "def get_posts(page_num):\n",
    "    global QUERY\n",
    "    posts = []\n",
    "    for page in range(page_num + 1):\n",
    "        # 페이지 넘기기\n",
    "        board_link = f\"https://www.fmkorea.com/search.php?mid=football_korean&search_keyword={QUERY}&search_target=title_content&page={page+1}\"\n",
    "        req = requests.get(board_link)\n",
    "        print(req.status_code)\n",
    "        soup = BeautifulSoup(req.text, 'html.parser')\n",
    "        # 전체 20개의 게시글의 링크를 posts에 append하는 과정\n",
    "        tds = soup.find_all('td', {'class': 'title hotdeal_var8'})\n",
    "        for td in tds:\n",
    "            post = td.find('a', {'class': 'hx'})\n",
    "            if post is not None:\n",
    "                posts.append(post['href'])\n",
    "    print(f\"총 {len(posts)}개의 글 링크를 찾았습니다.\")\n",
    "    # 게시글 링크 csv로 저장\n",
    "    post_file = open(f\"FMKOREA_{QUERY}_{page_num}pages_inner_links.csv\", mode='w', encoding='utf-8')\n",
    "    writer = csv.writer(post_file)\n",
    "    for post in posts:\n",
    "        writer.writerow([post])\n",
    "    post_file.close()\n",
    "    return posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "총 40개의 글 링크를 찾았습니다.\n"
     ]
    }
   ],
   "source": [
    "# 크롤링할 페이지 수 설정\n",
    "PAGES = 1\n",
    "# 게시글 링크 수집\n",
    "post_links = get_posts(PAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sda",
   "language": "python",
   "name": "sda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
