{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자동화하기\n",
    "# 이어서 쓸 때 save_to_file과 append_to_file 함수에 mode의 파라미터를 'a'로 변경해보기\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlencode\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from fake_useragent import UserAgent\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling failed, retrying... (1/5)\n",
      "Crawling failed, retrying... (2/5)\n",
      "Crawling failed, retrying... (3/5)\n",
      "Crawling failed, retrying... (4/5)\n",
      "Crawling failed, retrying... (5/5)\n",
      "Crawling failed after maximum retries.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_info(url, wait_time = 3, delay_time = 1):\n",
    "    data={}\n",
    "    max_retries = 3\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            chrome_options = Options()\n",
    "            chrome_options.add_argument('--headless')  # Headless 모드 활성화\n",
    "            driver = webdriver.Chrome(options=chrome_options)\n",
    "            driver.implicitly_wait(wait_time)\n",
    "            driver.get(url)\n",
    "            html = driver.page_source\n",
    "            time.sleep(delay_time)\n",
    "            driver.quit()\n",
    "            \n",
    "            soup = BeautifulSoup(html,'html.parser')\n",
    "           \n",
    "            title = soup.find('h3', {'class': 'tit_subject'}).get_text(strip=True)\n",
    "            user_id = soup.find('span', {'class':'txt_subject'}).split('|')[0].replace('작성자','').strip()\n",
    "            post_time = soup.find('span', {'class':'txt_subject'}).split('|')[1].replace('작성시간','').strip()\n",
    "            post_time = datetime.strptime(post_time, '%Y-%m-%d')\n",
    "            post = soup.find(id='article').get_text(strip=True)\n",
    "            view_cnt = soup.find('span', {'class':'txt_subject'}).split('|')[2].replace('조회수','').strip()\n",
    "            reply_cnt = int(soup.find(class_=\"num_total\").get_text(strip=True))\n",
    "            reply_content = []\n",
    "            if reply_cnt != 0:\n",
    "                comment_button = driver.find_element(By.CLASS_NAME, 'link_all')\n",
    "                comment_button.click()\n",
    "                \n",
    "                # 페이지 내의 코멘트들을 모두 찾자\n",
    "                cmt_all = soup.body.find('ul', id = 'commentList').find_all('li')\n",
    "    \n",
    "                # 찾은 코멘트들을 언패킹하자\n",
    "                for k in cmt_all:\n",
    "                    if k.div.span.find_all('span', class_ = 'txt_bar'):\n",
    "                        if k['class'] == ['reply_on']:\n",
    "                            cmt_reply = True\n",
    "                        else:\n",
    "                            cmt_reply = False\n",
    "                            \n",
    "                        cmt_writer = k.div.find('span', class_='sr_only').next_sibling\n",
    "                        cmt_time = k.div.span.find('span', class_='num_info').get_text()\n",
    "                        cmt_txt = k.div.find('span', class_='txt_detail').get_text(strip=True)\n",
    "                        reply_content.append({'author': cmt_writer, 'text': cmt_txt, 'time' : cmt_time})\n",
    "            data = {'title': title, 'user_id': user_id, 'post_time': post_time, 'post': post, 'view_cnt': view_cnt, 'reply_cnt': reply_cnt, 'reply_content': reply_content}\n",
    "            \n",
    "            # 댓글이 있다면 딕셔너리에 추가\n",
    "            if reply_cnt != 0:\n",
    "                for i, reply_info in enumerate(reply_content):\n",
    "                    data[f'reply_{i+1}_author'] = reply_info['author']\n",
    "                    data[f'reply_{i+1}_text'] = reply_info['text']\n",
    "                    data[f'reply_{i+1}_time'] = reply_info['time']\n",
    "            print(url, '완료')\n",
    "            break  # 성공적으로 크롤링이 완료되면 루프 종료\n",
    "        except Exception as e:\n",
    "            print(f\"Crawling failed, retrying... ({attempt+1}/{max_retries})\")\n",
    "            time.sleep(2)  # 2초 대기 후 재시도\n",
    "    else:\n",
    "        print(\"Crawling failed after maximum retries.\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "extract_info('https://m.cafe.daum.net/rocksoccer/ADs2/488585')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "# 설치 폴더에 주의합니다. \n",
    "\n",
    "driver.get('https://logins.daum.net/accounts/loginform.do?mobilefull=1&category=cafe&url=http%3A%2F%2Fm.cafe.daum.net%2F_myCafe%3Fnull')\n",
    "# 19년 5월부터 로그인 페이지 주소가 살짝 바뀌었네요. \n",
    "\n",
    "time.sleep(3)\n",
    "# 페이지 전환시에는 적당한 시간을 줍니다. \n",
    "# 1. 과도한 크롤링 방지.\n",
    "# 2. 페이지 전환이 완료되기 전에 다음 명령 실행되는 것 방지.\n",
    "#    AJAX를 사용한 페이지는 페이지 전환시 딜레이가 꼭 필요한 경우도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(url, wait_time=3, delay_time=1):\n",
    "    max_retries = 2\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            chrome_options = Options()\n",
    "            # chrome_options.add_argument('--headless')  # Headless 모드 활성화\n",
    "            # 원하는 User-Agent 설정\n",
    "            driver.get(url)\n",
    "            html = driver.page_source\n",
    "            time.sleep(delay_time)\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "            title = soup.find('h3', class_= 'tit_subject').get_text(strip=True)\n",
    "            user_info = soup.find('span', {'class': 'txt_subject'}).get_text(\"|\", strip=True).split('|')\n",
    "            user_id = user_info[0].replace('작성자', '').strip()\n",
    "            post_time = user_info[1].replace('작성시간', '').strip()\n",
    "            post_time = datetime.strptime(post_time, '%Y-%m-%d')\n",
    "            post = soup.find(id='article').get_text(strip=True)\n",
    "            view_cnt = user_info[2].replace('조회수', '').strip()\n",
    "            reply_cnt = int(soup.find(class_=\"num_total\").get_text(strip=True))\n",
    "            reply_content = []\n",
    "\n",
    "            print(f\"title: {title}\")\n",
    "            print(f\"user_id: {user_id}\")\n",
    "            print(f\"post_time: {post_time}\")\n",
    "            print(f\"post: {post}\")\n",
    "            print(f\"view_cnt: {view_cnt}\")\n",
    "            print(f\"reply_cnt: {reply_cnt}\")\n",
    "\n",
    "            if reply_cnt != 0:\n",
    "                comment_button = driver.find_element(By.CLASS_NAME, 'link_all')\n",
    "                comment_button.click()\n",
    "                time.sleep(1)  # 동적 콘텐츠 로딩 대기\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                cmt_all = soup.body.find('ul', id='commentList').find_all('li')\n",
    "\n",
    "                for k in cmt_all:\n",
    "                    if k.div.span.find_all('span', class_='txt_bar'):\n",
    "                        if 'reply_on' in k['class']:\n",
    "                            cmt_reply = True\n",
    "                        else:\n",
    "                            cmt_reply = False\n",
    "\n",
    "                        cmt_writer = k.div.find('span', class_='sr_only').next_sibling\n",
    "                        cmt_time = k.div.span.find('span', class_='num_info').get_text()\n",
    "                        cmt_txt = k.div.find('span', class_='txt_detail').get_text(strip=True)\n",
    "                        reply_content.append({'author': cmt_writer, 'text': cmt_txt, 'time': cmt_time})\n",
    "                        print(f\"comment: {cmt_writer}, {cmt_txt}, {cmt_time}\")\n",
    "\n",
    "            driver.quit()\n",
    "\n",
    "            print(url, '완료')\n",
    "            break  # 성공적으로 크롤링이 완료되면 루프 종료\n",
    "        except Exception as e:\n",
    "            print(f\"Crawling failed, retrying... ({attempt + 1}/{max_retries})\")\n",
    "            \n",
    "            time.sleep(2)  # 2초 대기 후 재시도\n",
    "    else:\n",
    "        print(\"Crawling failed after maximum retries.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling failed, retrying... (1/2)\n",
      "Crawling failed, retrying... (2/2)\n",
      "Crawling failed after maximum retries.\n"
     ]
    }
   ],
   "source": [
    "extract_info('https://m.cafe.daum.net/rocksoccer/ADs2/488585')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "# 설치 폴더에 주의합니다. \n",
    "\n",
    "driver.get('https://logins.daum.net/accounts/loginform.do?mobilefull=1&category=cafe&url=http%3A%2F%2Fm.cafe.daum.net%2F_myCafe%3Fnull')\n",
    "# 19년 5월부터 로그인 페이지 주소가 살짝 바뀌었네요. \n",
    "\n",
    "time.sleep(3)\n",
    "# 페이지 전환시에는 적당한 시간을 줍니다. \n",
    "# 1. 과도한 크롤링 방지.\n",
    "# 2. 페이지 전환이 완료되기 전에 다음 명령 실행되는 것 방지.\n",
    "#    AJAX를 사용한 페이지는 페이지 전환시 딜레이가 꼭 필요한 경우도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(url, wait_time=3, delay_time=1):\n",
    "    chrome_options = Options()\n",
    "    # chrome_options.add_argument('--headless')  # Headless 모드 활성화\n",
    "    # 원하는 User-Agent 설정\n",
    "    driver.get(url)\n",
    "    html = driver.page_source\n",
    "    time.sleep(delay_time)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    title = soup.find('h3', class_= 'tit_subject').get_text(strip=True)\n",
    "    user_info = soup.find('span', {'class': 'txt_subject'}).get_text(\"|\", strip=True).split('|')\n",
    "    user_id = user_info[1].replace('작성자', '').strip()\n",
    "    post_time = soup.find(class_='num_subject').contents[0].strip()\n",
    "    post = soup.find(id='article').get_text(strip=True)\n",
    "    view_cnt = soup.find_all(class_='num_subject')[1].text.strip()\n",
    "    reply_cnt = int(soup.find(class_=\"num_total\").get_text(strip=True))\n",
    "    print(reply_cnt)\n",
    "    reply_content = []\n",
    "\n",
    "    if reply_cnt != 0:\n",
    "        # 댓글 페이지로 이동\n",
    "\n",
    "        driver.get('https://m.cafe.daum.net/rocksoccer/ADs2/488585/comments')\n",
    "        time.sleep(1)\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        # 페이지 숫자 확인\n",
    "        cmt_page_max = int(soup.body.find('span', id=\"pagingNav\").find_all('span', class_=\"num_page\").pop().get_text())\n",
    "        print('cmt_page_max', cmt_page_max)\n",
    "    \n",
    "        # 페이지를 하나씩 넘기면서 캡쳐.. \n",
    "    \n",
    "        for i in range(cmt_page_max):\n",
    "            j = cmt_page_max-i\n",
    "        \n",
    "            # 캡처\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "            # 페이지 내의 코멘트들을 모두 찾자\n",
    "            cmt_all = soup.body.find('ul', id = 'commentList').find_all('li')\n",
    "        \n",
    "            # 찾은 코멘트들을 언패킹하자\n",
    "            for k in cmt_all:\n",
    "                if k.div.span.find_all('span', class_ = 'txt_bar'):\n",
    "                    if k['class'] == ['reply_on']:\n",
    "                        cmt_reply = True\n",
    "                        print('ㄴ', end='') #대댓글을 따로 처리? 걍 또다른 댓글이라고 치자..\n",
    "                    else:\n",
    "                        cmt_reply = False\n",
    "                    \n",
    "                    cmt_num = inp_num +'_'+ k['id'].split('comment_')[1]\n",
    "                    cmt_writer = k.div.find('span', class_='sr_only').next_sibling\n",
    "                    cmt_time = k.div.span.find('span', class_='num_info').get_text()\n",
    "                    cmt_txt = k.div.find('span', class_='txt_detail').get_text(strip=True)\n",
    "                \n",
    "                    # 언패킹한 결과물을 화면 출력\n",
    "                    print(cmt_num, '[', cmt_writer,']', cmt_time, cmt_txt)\n",
    "\n",
    "            # 페이지가 0으로 넘어가지 않도록 if문 작성\n",
    "        \n",
    "            if j > 1:\n",
    "                #페이지 이동\n",
    "                driver.get('http://m.cafe.daum.net/{0}/{1}/{2}/comments?prev_page = {3}&mode=regular&depth={4}&page={5}'.format(CAFE_NAME, BOARD_NAME, inp_num, j, '0002100000', (j-1)))\n",
    "                time.sleep(2)\n",
    "    print(url, '완료')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "cmt_page_max 2\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'CAFE_NAME' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mextract_info\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://m.cafe.daum.net/rocksoccer/ADs2/488585\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[38], line 64\u001b[0m, in \u001b[0;36mextract_info\u001b[1;34m(url, wait_time, delay_time)\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[38;5;66;03m# 페이지가 0으로 넘어가지 않도록 if문 작성\u001b[39;00m\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m j \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     63\u001b[0m             \u001b[38;5;66;03m#페이지 이동\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m             driver\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp://m.cafe.daum.net/\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m/comments?prev_page = \u001b[39m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;124m&mode=regular&depth=\u001b[39m\u001b[38;5;132;01m{4}\u001b[39;00m\u001b[38;5;124m&page=\u001b[39m\u001b[38;5;132;01m{5}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[43mCAFE_NAME\u001b[49m, BOARD_NAME, inp_num, j, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0002100000\u001b[39m\u001b[38;5;124m'\u001b[39m, (j\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n\u001b[0;32m     65\u001b[0m             time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(url, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m완료\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CAFE_NAME' is not defined"
     ]
    }
   ],
   "source": [
    "extract_info('https://m.cafe.daum.net/rocksoccer/ADs2/488585')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reply_cnt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mreply_cnt\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'reply_cnt' is not defined"
     ]
    }
   ],
   "source": [
    "reply_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sda",
   "language": "python",
   "name": "sda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
