{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "출처 : https://arxiv.org/pdf/1607.01759.pdf\n",
    "\n",
    "초록\n",
    "\n",
    "위 논문은 텍스트 분류를 위한 간단하고 효과적인 baseline을 탐구한다. 우리의 실험은 fastText라는 빠른 text classifier가 학습과 평가에서 다른 딥러닝 분류기들과 비슷한 정확도를 보임과 동시에 속도가 빠름을 보여준다. 멀티 코어 CPU로 1억개의 단어들을 십분안에 학습할 수 있고 5000개의 문장들을 312000개의 클래스로 일분 안에 분류할 수 있다.\n",
    "\n",
    "\n",
    "\n",
    "1. Introduction\n",
    "\n",
    "텍스트 분류는 NLP에서 매우 중요한 작업이다(가령, 웹 검색, 정보 탐색, ranking and document classification 등) 최근에 신경망을 기반으로 한 모델들이 매우 인기있다. 이러한 모델들이 실전에서 좋은 성능을 보이긴 하지만, train과 test에서 상대적으로 느리며 매우 큰 데이터셋을 사용하기에 힘들다.\n",
    "\n",
    " 한편, linear classifier은 텍스트 분류 문제에 대한 강력한 baseline으로 여겨진다. 그들의 단순함에도 불구하고, 올바른 feature들이 주어지면, 좋은 성능을 보여주며 매우 많은 corpus를 처리할 수 있는 가능성 또한 있다. \n",
    "\n",
    " 위 논문에서, 우리는 텍스트 분류의 맥락에서 많은 output 차원을 가진 거대 corpus를 scale할 수 있는 방법들을 탐구하고자 한다. 최근 효과적인 word representation learning에 감명받아, 우리는 rank constraint 와 fast loss approximation을 갖고 있는 linear model들이 최신 기술들과 비슷한 정확도를 보이며 10분 안에 1억개의 단어들을 학습할 수 있음을 보여주려 한다. 우리는 fastText를 tag prediction과 sentiment analysis 두가지 task에 활용하여 평가하고자 한다.\n",
    "\n",
    "\n",
    "\n",
    "2. Model Architecture\n",
    "\n",
    "문장 분류를 위한 간단하고 효율적인 baseline은 문장들을 bag of Words(boW)로 표현하고 linear classifier(가령, logistic regression 혹은 Support Vector Machine)에 학습시키는 것이다. 그러나, linear classifier들은 feature와 class 간에 파라미터를 공유하지 않기에, output차원이 클 때에는 일반화가 잘 이루어지지 않는다.(어떤 클래스들은 매우 작은 예시만을 갖기에) 이 문제를 해결하기 위한 일반적인 solution으로 linear classifier를 낮은 rank matrices로 분해하거나 multilayer-neural-networs를 사용하는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
